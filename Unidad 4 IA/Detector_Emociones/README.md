Link del Google Drive (donde se encuentran el Dataset, el mejor modelo generado, el modelo final que puede ser o no el mejor, las clases [osea las emociones] en un .JSON y el VIDEO testeando el modelo):

https://drive.google.com/drive/folders/1dFyUTqx9YDUuG0sxlsJ4v_gjZAmBc5zD?usp=sharing

Link directo del Video que esta en el Drive:

https://drive.google.com/file/d/1v3Ut_UjAkcL8Lezs9rVMhijRdZAyqHXP/view?usp=sharing

ğŸ“· SISTEMA DE DETECCIÃ“N DE EMOCIONES CON DEEP LEARNING Y RECONOCIMIENTO FACIAL EN TIEMPO REAL

Elaborado por:

ğŸ‘¨â€ğŸ’» Jonatan Arnoldo Valdez Ayala

ğŸ‘¨â€ğŸ’» Jose Enrique Espindola Leyva

ğŸ“„ DESCRIPCIÃ“N

Este proyecto implementa un Sistema de Reconocimiento de Emociones basado en Deep Learning, utilizando el modelo preentrenado MobileNetV2, ajustado mediante transfer learning para clasificar cuatro emociones faciales: Feliz, Triste, Enojado y Neutral.

El sistema trabaja con tres componentes principales:

ğŸ§  Un script de entrenamiento para generar el modelo.

ğŸ“Š Un mÃ³dulo de evaluaciÃ³n con matriz de confusiÃ³n.

ğŸ¥ Una aplicaciÃ³n en tiempo real que detecta el rostro y predice la emociÃ³n usando la cÃ¡mara web.

La detecciÃ³n facial se realiza con MediaPipe, mientras que el anÃ¡lisis emocional se ejecuta con TensorFlow/Keras y el modelo entrenado.

âš™ï¸ FUNCIONALIDADES

ğŸ”¹ 1. Entrenamiento del Modelo (entrenamiento.py)

Uso de MobileNetV2 como red base para transfer learning.

Preprocesamiento de imÃ¡genes con ImageDataGenerator.

Entrenamiento en dos fases (capas congeladas y descongeladas).

Guardado automÃ¡tico del mejor modelo (mejor_modelo.h5).

GeneraciÃ³n de archivo JSON con las clases del dataset.

ğŸ”¹ 2. DetecciÃ³n en Tiempo Real (camara.py)

ActivaciÃ³n de la cÃ¡mara mediante OpenCV.

DetecciÃ³n del rostro con MediaPipe Face Detection.

Recorte, reescalado y preprocesamiento de la cara detectada.

PredicciÃ³n de emociÃ³n en tiempo real con el modelo entrenado.

VisualizaciÃ³n en pantalla del recuadro facial y porcentaje de confianza.

FinalizaciÃ³n con la tecla "ESC".

ğŸ”¹ 3. AnÃ¡lisis del Modelo (matriz_confusion.py)

Carga del modelo y las clases usando MobileNetV2.

EvaluaciÃ³n del conjunto de validaciÃ³n del dataset.

GeneraciÃ³n automÃ¡tica de:

ğŸ“Š Matriz de confusiÃ³n

ğŸ§¾ Reporte de clasificaciÃ³n (precision, recall, f1-score)


â–¶ï¸ EJECUCIÃ“N

ğŸ“˜ La ejecuciÃ³n se divide de la siguiente forma:

Para entrenar el modelo:
python entrenamiento.py

Para analizar el rendimiento del modelo:
python matriz_confusion.py

Para usar la cÃ¡mara y detectar emociones en tiempo real:
python camara.py
